{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7328ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c5e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e48f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models listed: 9\n",
      "Testing gemini-2.5-flash ... ‚úîÔ∏è ok\n",
      "Testing gemini-2.5-pro ... ‚úñ quota_exceeded_free_tier\n",
      "Testing gemini-2.0-flash ... ‚úñ quota_exceeded_free_tier\n",
      "Testing gemini-2.0-flash-001 ... ‚úñ quota_exceeded_free_tier\n",
      "Testing gemini-2.0-flash-lite-001 ... ‚úñ quota_exceeded_free_tier\n",
      "Testing gemini-2.0-flash-lite ... ‚úñ quota_exceeded_free_tier\n",
      "Testing gemini-2.5-flash-lite ... ‚úîÔ∏è ok\n",
      "\n",
      "--- R√©sum√© ---\n",
      "Mod√®les consid√©r√©s gratuits (acceptent la micro-requ√™te): 2\n",
      " * gemini-2.5-flash\n",
      " * gemini-2.5-flash-lite\n",
      "\n",
      "D√©taill√© (tous):\n",
      "- gemini-2.5-flash -> ok=True reason=200 OK\n",
      "- gemini-2.5-pro -> ok=False reason=quota_exceeded_free_tier\n",
      "  response_snippet: {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/gene\n",
      "- gemini-2.0-flash -> ok=False reason=quota_exceeded_free_tier\n",
      "  response_snippet: {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/ge\n",
      "- gemini-2.0-flash-001 -> ok=False reason=quota_exceeded_free_tier\n",
      "  response_snippet: {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleap\n",
      "- gemini-2.0-flash-lite-001 -> ok=False reason=quota_exceeded_free_tier\n",
      "  response_snippet: {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\\n* Quota exceeded for metric: generativelanguage.googleapis.c\n",
      "- gemini-2.0-flash-lite -> ok=False reason=quota_exceeded_free_tier\n",
      "  response_snippet: {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\\n* Quota exceeded for metric: generativelanguage.googleapis.c\n",
      "- gemini-2.5-flash-lite -> ok=True reason=200 OK\n",
      "- embedding-001 -> ok=False reason=list_says_no_generate\n",
      "  response_snippet: {\"name\": \"models/embedding-001\", \"version\": \"001\", \"displayName\": \"Embedding 001\", \"description\": \"Obtain a distributed representation of a text.\", \"inputTokenLimit\": 2048, \"outputTokenLimit\": 1, \"supportedGenerationMethods\": [\"embedContent\"]}\n",
      "- text-embedding-004 -> ok=False reason=list_says_no_generate\n",
      "  response_snippet: {\"name\": \"models/text-embedding-004\", \"version\": \"004\", \"displayName\": \"Text Embedding 004\", \"description\": \"Obtain a distributed representation of a text.\", \"inputTokenLimit\": 2048, \"outputTokenLimit\": 1, \"supportedGenerationMethods\": [\"embedContent\"]}\n"
     ]
    }
   ],
   "source": [
    "# Notebook : detect_free_models_for_key.ipynb\n",
    "# Usage: coller ta cl√© dans API_KEY et lancer.\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "API_KEY = \"AIzaSyASvsVlSyFWcWN2bw9KDtBCwzURKUNatlE\"  # <-- mets ta cl√© ici\n",
    "BASE_URL = \"https://generativelanguage.googleapis.com/v1\"  # essaye v1 puis v1beta si besoin\n",
    "\n",
    "def list_models(api_key: str, base_url: str = BASE_URL) -> List[dict]:\n",
    "    url = f\"{base_url}/models?key={api_key}\"\n",
    "    r = requests.get(url, timeout=15)\n",
    "    if r.status_code != 200:\n",
    "        print(\"Erreur list_models:\", r.status_code, r.text)\n",
    "        return []\n",
    "    return r.json().get(\"models\", [])\n",
    "\n",
    "def can_attempt_generate(model: dict) -> bool:\n",
    "    # heuristique : quand la r√©ponse list_models contient un champ indiquant m√©thodes support√©es\n",
    "    # on v√©rifie s'il y a generate / generateContent support info. Sinon on laisse passer.\n",
    "    # (adaptable selon le contenu r√©el de la response)\n",
    "    for k in (\"supportedMethods\", \"supportedGenerationMethods\", \"supportedExecutionMethods\"):\n",
    "        if k in model:\n",
    "            vals = model.get(k) or []\n",
    "            # certains objets donnent des sous-champs type strings\n",
    "            if isinstance(vals, list):\n",
    "                for v in vals:\n",
    "                    if \"generate\" in str(v).lower() or \"generatecontent\" in str(v).lower():\n",
    "                        return True\n",
    "            elif isinstance(vals, str):\n",
    "                if \"generate\" in vals.lower():\n",
    "                    return True\n",
    "            return False\n",
    "    # Si on n'a pas d'info, on tente quand m√™me (beaucoup de listes publiques n'ont pas ce champ)\n",
    "    return True\n",
    "\n",
    "def test_model_free(api_key: str, model_name: str, base_url: str = BASE_URL, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Teste un mod√®le en utilisant le nouveau format Gemini 2025.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/models/{model_name}:generateContent?key={api_key}\"\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [{\"text\": \"hi\"}]\n",
    "            }\n",
    "        ],\n",
    "        \"generationConfig\": {\n",
    "            \"maxOutputTokens\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        r = requests.post(url, json=payload, headers=headers, timeout=15)\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"reason\": f\"exception:{e}\", \"status\": None, \"resp\": None}\n",
    "\n",
    "    status = r.status_code\n",
    "    text = r.text.lower()\n",
    "\n",
    "    if debug:\n",
    "        print(\"status:\", status)\n",
    "        print(\"raw:\", r.text[:1000])\n",
    "\n",
    "    # 200 = gratuit + accessible\n",
    "    if status == 200:\n",
    "        return {\"ok\": True, \"reason\": \"200 OK\", \"status\": 200, \"resp\": r.json()}\n",
    "\n",
    "    # quota free tier atteint (mais mod√®le gratuit normalement)\n",
    "    if \"quota\" in text or \"free tier\" in text or \"freetier\" in text:\n",
    "        return {\"ok\": False, \"reason\": \"quota_exceeded_free_tier\", \"status\": status, \"resp\": r.text}\n",
    "\n",
    "    # mod√®le pas accessible / pas gratuit\n",
    "    if status in (401, 403):\n",
    "        return {\"ok\": False, \"reason\": \"forbidden\", \"status\": status, \"resp\": r.text}\n",
    "\n",
    "    if status == 404:\n",
    "        return {\"ok\": False, \"reason\": \"not_found\", \"status\": 404, \"resp\": r.text}\n",
    "\n",
    "    if status == 429:\n",
    "        return {\"ok\": False, \"reason\": \"rate_limited\", \"status\": 429, \"resp\": r.text}\n",
    "\n",
    "    return {\"ok\": False, \"reason\": \"other_error\", \"status\": status, \"resp\": r.text}\n",
    "\n",
    "\n",
    "def detect_free_models_for_key(api_key: str, base_url: str = BASE_URL, limit_tests: int = None):\n",
    "    models = list_models(api_key, base_url)\n",
    "    print(f\"Total models listed: {len(models)}\")\n",
    "    results = []\n",
    "    tested = 0\n",
    "    for m in models:\n",
    "        # model object sometimes contient 'name' = 'models/xyz'\n",
    "        name = m.get(\"name\") or m.get(\"modelId\") or m.get(\"id\")\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        # normalize: if name contains 'models/' strip it for endpoint\n",
    "        if name.startswith(\"models/\"):\n",
    "            model_id = name.split(\"models/\")[-1]\n",
    "        else:\n",
    "            model_id = name\n",
    "\n",
    "        # optional: skip obviously non-gen models by checking metadata\n",
    "        if not can_attempt_generate(m):\n",
    "            reason = \"list_says_no_generate\"\n",
    "            results.append((model_id, False, reason, m))\n",
    "            continue\n",
    "\n",
    "        print(f\"Testing {model_id} ...\", end=\" \")\n",
    "        out = test_model_free(api_key, model_id, base_url)\n",
    "        tested += 1\n",
    "        if out[\"ok\"]:\n",
    "            print(\"‚úîÔ∏è ok\")\n",
    "            results.append((model_id, True, out[\"reason\"], out[\"resp\"]))\n",
    "        else:\n",
    "            print(\"‚úñ\", out[\"reason\"])\n",
    "            results.append((model_id, False, out[\"reason\"], out[\"resp\"]))\n",
    "\n",
    "        # small delay to avoid immediate rate-limits\n",
    "        time.sleep(0.35)\n",
    "\n",
    "        if limit_tests and tested >= limit_tests:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# LANCEMENT\n",
    "res = detect_free_models_for_key(API_KEY, base_url=BASE_URL, limit_tests=None)\n",
    "\n",
    "# affichage synth√©tique\n",
    "free = [r for r in res if r[1] is True]\n",
    "print(\"\\n--- R√©sum√© ---\")\n",
    "print(\"Mod√®les consid√©r√©s gratuits (acceptent la micro-requ√™te):\", len(free))\n",
    "for f in free:\n",
    "    print(\" *\", f[0])\n",
    "print(\"\\nD√©taill√© (tous):\")\n",
    "for r in res:\n",
    "    name, ok, reason, resp = r\n",
    "    print(f\"- {name} -> ok={ok} reason={reason}\")\n",
    "    # si ambiguous, print response snippet\n",
    "    if not ok:\n",
    "        snippet = \"\"\n",
    "        if isinstance(resp, dict):\n",
    "            snippet = json.dumps(resp)[:500]\n",
    "        else:\n",
    "            snippet = str(resp)[:500]\n",
    "        print(\"  response_snippet:\", snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"TA_CLE_ICI\"\n",
    "\n",
    "def list_models(api_key):\n",
    "    url = \"https://generativelanguage.googleapis.com/v1beta/models\"\n",
    "    params = {\"key\": api_key}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Erreur API :\", response.text)\n",
    "        return None\n",
    "    \n",
    "    return response.json().get(\"models\", [])\n",
    "\n",
    "def filter_free_models(models):\n",
    "    free_models = []\n",
    "\n",
    "    for m in models:\n",
    "        # Google tague les mod√®les gratuits avec:\n",
    "        # - absence de \"defaultPoint\"\n",
    "        # - ou presence d'un point \"free\"\n",
    "        # - ou pas de \"pricingTier\"\n",
    "        tier = m.get(\"defaultPoint\", \"\")\n",
    "        pricing = m.get(\"pricingTier\", \"\")\n",
    "        \n",
    "        if (\"free\" in tier.lower()) or (\"free\" in pricing.lower()) or pricing == \"\":\n",
    "            free_models.append(m)\n",
    "\n",
    "    return free_models\n",
    "\n",
    "\n",
    "# R√©cup√©rer tous les mod√®les\n",
    "models = list_models(API_KEY)\n",
    "\n",
    "if not models:\n",
    "    print(\"Aucun mod√®le trouv√©.\")\n",
    "else:\n",
    "    print(f\"Total mod√®les trouv√©s : {len(models)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Filtrer les mod√®les gratuits\n",
    "    free = filter_free_models(models)\n",
    "\n",
    "    if free:\n",
    "        print(f\"üìå Mod√®les gratuits d√©tect√©s ({len(free)}) :\\n\")\n",
    "        for m in free:\n",
    "            print(\"Nom :\", m.get(\"name\"))\n",
    "            print(\"Description :\", m.get(\"description\"))\n",
    "            print(\"Tier :\", m.get(\"pricingTier\"))\n",
    "            print(\"-\" * 40)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucun mod√®le gratuit d√©tect√© avec cette cl√©.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
