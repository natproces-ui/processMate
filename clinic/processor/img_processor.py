"""
Processeur d'images 
Extrait les workflows depuis des images et retourne au format Table1Row
+ Am√©lioration de workflows existants
VERSION AM√âLIOR√âE : Prompt adaptatif avec analyse r√©flexive
"""

import google.generativeai as genai
from PIL import Image
import io
import json
import re
from typing import Dict, List, Any, Tuple
import os
import logging
import asyncio
from functools import partial
import time
import random
from manager.model_manager import GeminiModelManager, GeminiModel

# Import des prompts depuis les fichiers d√©di√©s
from prompts.extract_prompt import get_extraction_prompt
from prompts.enhance_prompt import get_improvement_prompt
from prompts.verify_prompt import get_verification_prompt

logger = logging.getLogger(__name__)

class ImageProcessor:
    def __init__(self):
        """
        Utilise le ModelManager pour g√©rer les retries et fallbacks
        """
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY non configur√©e")
        
        self.model_manager = GeminiModelManager(api_key)
        self.request_timeout = 600
    
    async def extract_workflow(self, image_data: bytes, content_type: str) -> Dict[str, Any]:
        """
        Extrait un workflow ET enrichissements depuis une image
        
        Args:
            image_data: Donn√©es binaires de l'image
            content_type: Type MIME de l'image
        
        Returns:
            Dict avec title, workflow, enrichments et m√©tadonn√©es
        """
        try:
            image = Image.open(io.BytesIO(image_data))
            
            max_size = 1024
            if max(image.size) > max_size:
                image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=85, optimize=True)
                image = Image.open(buffer)
                logger.info(f"Image optimis√©e: {image.size} px, ~{len(buffer.getvalue())} bytes")
            
            prompt = get_extraction_prompt()
            
            async def _extract_task(model_name: str):
                logger.info(f"üîç Extraction avec {model_name}")
                
                model = self.model_manager.get_model(model_name)
                
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        model.generate_content,
                        [prompt, image]
                    ),
                    timeout=self.request_timeout
                )
                
                return response
            
            result = await self.model_manager.execute_with_fallback(
                _extract_task,
                task_name="Extraction de workflow depuis image"
            )
            
            if not result["success"]:
                raise ValueError(result["message"])
            
            response = result["result"]
            
            logger.info(f"‚úì R√©ponse Gemini re√ßue ({len(response.text)} caract√®res)")
            
            workflow_data, title, enrichments_dict = self._parse_gemini_response(response.text)
            
            validated = self._validate_and_normalize_workflow(workflow_data)
            
            metadata = self._build_metadata(validated, image)
            metadata["model_used"] = result["model_used"]
            metadata["attempts"] = result["attempts"]
            metadata["enrichments_count"] = len(enrichments_dict)
            
            return {
                "title": title,
                "workflow": validated,
                "enrichments": enrichments_dict,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction workflow: {str(e)}", exc_info=True)
            raise ValueError(f"Impossible d'extraire le workflow: {str(e)}")
    
    async def improve_workflow(self, workflow: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        Am√©liore un workflow existant avec Gemini 2.5 Flash
        
        Args:
            workflow: Tableau Table1Row[] existant
        
        Returns:
            Dict avec workflow am√©lior√© et m√©tadonn√©es de comparaison
        """
        try:
            prompt = get_improvement_prompt(workflow)
            
            async def _improve_task(model_name: str):
                logger.info(f"üîß Am√©lioration avec {model_name}")
                
                model = self.model_manager.get_model(model_name)
                
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        model.generate_content,
                        prompt
                    ),
                    timeout=90
                )
                
                return response
            
            result = await self.model_manager.execute_with_fallback(
                _improve_task,
                task_name="Am√©lioration de workflow"
            )
            
            if not result["success"]:
                raise ValueError(result["message"])
            
            response = result["result"]
            
            logger.info(f"‚úì R√©ponse Gemini am√©lioration re√ßue ({len(response.text)} caract√®res)")
            
            improved_data, _, _ = self._parse_gemini_response(response.text)
            
            validated = self._validate_and_normalize_workflow(improved_data)
            
            comparison = self._build_comparison_metadata(workflow, validated)
            comparison["model_used"] = result["model_used"]
            comparison["attempts"] = result["attempts"]
            
            return {
                "workflow": validated,
                "metadata": comparison
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur am√©lioration workflow: {str(e)}", exc_info=True)
            raise ValueError(f"Impossible d'am√©liorer le workflow: {str(e)}")
    
    async def verify_extraction(self, 
                               image_data: bytes, 
                               content_type: str,
                               extracted_workflow: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        V√©rifie l'extraction en comparant l'image et le workflow JSON
        Identifie les √©l√©ments manquants ou mal extraits
        
        Args:
            image_data: Donn√©es binaires de l'image originale
            content_type: Type MIME de l'image
            extracted_workflow: Workflow d√©j√† extrait √† v√©rifier
        
        Returns:
            Dict avec analyse des erreurs et √©l√©ments manquants
        """
        try:
            image = Image.open(io.BytesIO(image_data))
            
            max_size = 1024
            if max(image.size) > max_size:
                image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                buffer = io.BytesIO()
                image.save(buffer, format='JPEG', quality=85, optimize=True)
                image = Image.open(buffer)
            
            prompt = get_verification_prompt(extracted_workflow)
            
            async def _verify_task(model_name: str):
                logger.info(f"üîç V√©rification avec {model_name}")
                
                model = self.model_manager.get_model(model_name)
                
                response = await asyncio.wait_for(
                    asyncio.to_thread(
                        model.generate_content,
                        [prompt, image]
                    ),
                    timeout=self.request_timeout
                )
                
                return response
            
            result = await self.model_manager.execute_with_fallback(
                _verify_task,
                task_name="V√©rification de workflow"
            )
            
            if not result["success"]:
                raise ValueError(result["message"])
            
            response = result["result"]
            
            logger.info(f"‚úì V√©rification re√ßue ({len(response.text)} caract√®res)")
            
            verification_result = self._parse_verification_response(response.text)
            verification_result["model_used"] = result["model_used"]
            verification_result["attempts"] = result["attempts"]
            
            return verification_result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification workflow: {str(e)}", exc_info=True)
            raise ValueError(f"Impossible de v√©rifier le workflow: {str(e)}")
    
    def _parse_gemini_response(self, text: str) -> Tuple[List[Dict[str, str]], str, Dict[str, Dict]]:
        """Parse la r√©ponse JSON de Gemini et retourne (workflow, title, enrichments_dict)"""
        try:
            text = text.strip()
            
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                text = json_match.group(0)
            
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```\s*', '', text)
            
            data = json.loads(text)
            
            title = data.get("title", "").strip()
            if not title:
                title = "Processus m√©tier"
            
            if "workflow" in data:
                workflow = data["workflow"]
            elif isinstance(data, list):
                workflow = data
            else:
                raise ValueError("Format JSON invalide - cl√© 'workflow' manquante")
            
            if not workflow or len(workflow) == 0:
                raise ValueError("Workflow vide retourn√© par Gemini")
            
            enrichments_list = data.get("enrichments", [])
            enrichments_dict = {}
            for enr in enrichments_list:
                task_id = enr.get("id_tache", "")
                if task_id:
                    enrichments_dict[task_id] = {
                        "id_tache": task_id,
                        "descriptif": enr.get("descriptif", "").strip(),
                        "duree_estimee": enr.get("duree_estimee", "").strip(),
                        "frequence": enr.get("frequence", "").strip(),
                        "kpi": enr.get("kpi", "").strip()
                    }
            
            logger.info(f"‚úì Titre: '{title}' - {len(workflow)} √©tapes, {len(enrichments_dict)} enrichies")
            return workflow, title, enrichments_dict
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {str(e)}\nTexte: {text[:500]}")
            raise ValueError(f"R√©ponse non-JSON de Gemini: {str(e)}")
    
    def _validate_and_normalize_workflow(self, workflow: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """Valide et normalise au format Table1Row strict"""
        validated = []
        all_ids = [str(step.get("id", "")) for step in workflow]
        
        for idx, step in enumerate(workflow):
            normalized = {
                "id": str(step.get("id", str(idx + 1))),
                "√©tape": str(step.get("√©tape", "")).strip() or f"√âtape {idx + 1}",
                "typeBpmn": str(step.get("typeBpmn", "Task")),
                "d√©partement": str(step.get("d√©partement", "")).strip(),
                "acteur": str(step.get("acteur", "")).strip(),
                "condition": str(step.get("condition", "")).strip(),
                "outputOui": str(step.get("outputOui", "")).strip(),
                "outputNon": str(step.get("outputNon", "")).strip(),
                "outil": str(step.get("outil", "")).strip()
            }
            
            valid_types = ["StartEvent", "Task", "ExclusiveGateway", "EndEvent"]
            if normalized["typeBpmn"] not in valid_types:
                logger.warning(f"‚ö†Ô∏è Type invalide '{normalized['typeBpmn']}' ‚Üí Task")
                normalized["typeBpmn"] = "Task"
            
            if normalized["typeBpmn"] == "ExclusiveGateway":
                if not normalized["condition"]:
                    normalized["condition"] = normalized["√©tape"] or "D√©cision"
            else:
                normalized["condition"] = ""
                normalized["outputNon"] = ""
            
            if normalized["outputOui"] and normalized["outputOui"] not in all_ids:
                logger.warning(f"‚ö†Ô∏è OutputOui invalide pour {normalized['id']}")
            
            if normalized["outputNon"] and normalized["outputNon"] not in all_ids:
                logger.warning(f"‚ö†Ô∏è OutputNon invalide pour {normalized['id']}")
            
            validated.append(normalized)
        
        logger.info(f"‚úÖ Workflow valid√©: {len(validated)} √©tapes")
        return validated
    
    def _build_metadata(self, workflow: List[Dict[str, str]], image: Image.Image) -> Dict[str, Any]:
        """Construit les m√©tadonn√©es du workflow"""
        actors = list(set(s["acteur"] for s in workflow if s["acteur"]))
        departments = list(set(s["d√©partement"] for s in workflow if s["d√©partement"]))
        tools = list(set(s["outil"] for s in workflow if s["outil"]))
        
        return {
            "image_info": {
                "size": f"{image.width}x{image.height}",
                "format": image.format
            },
            "workflow_stats": {
                "total_steps": len(workflow),
                "start_events": sum(1 for s in workflow if s["typeBpmn"] == "StartEvent"),
                "end_events": sum(1 for s in workflow if s["typeBpmn"] == "EndEvent"),
                "tasks": sum(1 for s in workflow if s["typeBpmn"] == "Task"),
                "gateways": sum(1 for s in workflow if s["typeBpmn"] == "ExclusiveGateway")
            },
            "business_info": {
                "actors": actors if actors else ["Non sp√©cifi√©"],
                "actors_count": len(actors),
                "departments": departments if departments else ["Non sp√©cifi√©"],
                "departments_count": len(departments),
                "tools": tools if tools else ["Non sp√©cifi√©"],
                "tools_count": len(tools)
            }
        }
    
    def _build_comparison_metadata(self, 
                                   original: List[Dict[str, str]], 
                                   improved: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        Construit les m√©tadonn√©es de comparaison avant/apr√®s am√©lioration
        """
        original_actors = set(s["acteur"] for s in original if s["acteur"])
        improved_actors = set(s["acteur"] for s in improved if s["acteur"])
        
        original_departments = set(s["d√©partement"] for s in original if s["d√©partement"])
        improved_departments = set(s["d√©partement"] for s in improved if s["d√©partement"])
        
        original_tools = set(s["outil"] for s in original if s["outil"])
        improved_tools = set(s["outil"] for s in improved if s["outil"])
        
        return {
            "comparison": {
                "actors_added": list(improved_actors - original_actors),
                "actors_removed": list(original_actors - improved_actors),
                "departments_added": list(improved_departments - original_departments),
                "departments_removed": list(original_departments - improved_departments),
                "tools_added": list(improved_tools - original_tools),
                "tools_removed": list(original_tools - original_tools)
            },
            "workflow_stats": {
                "total_steps": len(improved),
                "start_events": sum(1 for s in improved if s["typeBpmn"] == "StartEvent"),
                "end_events": sum(1 for s in improved if s["typeBpmn"] == "EndEvent"),
                "tasks": sum(1 for s in improved if s["typeBpmn"] == "Task"),
                "gateways": sum(1 for s in improved if s["typeBpmn"] == "ExclusiveGateway")
            },
            "improvements": {
                "steps_reformulated": sum(
                    1 for i, orig in enumerate(original) 
                    if i < len(improved) and orig["√©tape"] != improved[i]["√©tape"]
                ),
                "actors_clarified": len(improved_actors) - len(original_actors),
                "tools_identified": len(improved_tools) - len(original_tools)
            }
        }
    
    def _parse_verification_response(self, text: str) -> Dict[str, Any]:
        """Parse la r√©ponse de v√©rification de Gemini"""
        try:
            text = text.strip()
            
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                text = json_match.group(0)
            
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```\s*', '', text)
            
            data = json.loads(text)
            
            if "verification_result" in data:
                result = data["verification_result"]
            else:
                result = data
            
            required_keys = ["accuracy", "total_extracted", "total_expected", "errors"]
            for key in required_keys:
                if key not in result:
                    logger.warning(f"‚ö†Ô∏è Cl√© manquante dans v√©rification: {key}")
                    result[key] = 0 if key != "errors" else []
            
            logger.info(f"‚úì V√©rification pars√©e: {result.get('missing_count', 0)} √©l√©ments manquants")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing v√©rification: {str(e)}\nTexte: {text[:500]}")
            return {
                "accuracy": 0,
                "total_extracted": 0,
                "total_expected": 0,
                "missing_count": 0,
                "errors": [
                    {
                        "category": "Erreur syst√®me",
                        "items": [
                            {
                                "type": "step",
                                "description": f"Erreur de parsing: {str(e)}",
                                "location": "Syst√®me",
                                "severity": "critical"
                            }
                        ]
                    }
                ]
            }